"""
ÂÖ¨ÂÖ±ÂèØËßÜÂåñÂ∑•ÂÖ∑Ê®°Âùó
ÂåÖÂê´ÊâÄÊúâÊ®°ÂûãÈÄöÁî®ÁöÑÂõæÂÉèÂ§ÑÁêÜÂíåÂèØËßÜÂåñ‰øùÂ≠òÂáΩÊï∞
"""

import os
import cv2
import torch
import numpy as np
from PIL import Image
from pathlib import Path


def process_image(args, img_path, text, transform):
    """Â§ÑÁêÜÂçïÂº†ÂõæÂÉèÔºåËøîÂõûtransformÂêéÁöÑÂõæÂÉèÁî®‰∫éÊ®°ÂûãÊé®ÁêÜÂíåÂéüÂßãÂõæÂÉèÁî®‰∫éÂèØËßÜÂåñ
    
    Args:
        args: ÂèÇÊï∞ÂØπË±°ÔºåÂåÖÂê´modalityÁ≠âÈÖçÁΩÆ
        img_path: ÂõæÂÉèË∑ØÂæÑ
        text: ÊñáÊú¨ÊèèËø∞
        transform: ÂõæÂÉèÂèòÊç¢ÂáΩÊï∞
        
    Returns:
        ÂØπ‰∫éRGBTÊ®°ÊÄÅ: (img_tensor, img_mask, pil_img_original, pil_img_ir)
        ÂØπ‰∫éÂÖ∂‰ªñÊ®°ÊÄÅ: (img_tensor, img_mask, pil_img_original)
    """
    pil_img_original = None  # ‰øùÂ≠òÂéüÂßãRGBÂõæÂÉèÁî®‰∫éÂèØËßÜÂåñ
    pil_img_ir = None  # ‰øùÂ≠òÂéüÂßãIRÂõæÂÉèÁî®‰∫éÂèØËßÜÂåñ
    
    if args.modality == 'rgbt':
        # Â∞ùËØïËá™Âä®ÈÖçÂØπRGBÂíåIRÂõæÂÉè
        if '/rgb/' in img_path:
            rgb_path = img_path
            ir_path = img_path.replace('/rgb/', '/ir/')
        elif '/ir/' in img_path:
            ir_path = img_path
            rgb_path = img_path.replace('/ir/', '/rgb/')
        else:
            rgb_path = img_path
            ir_path = img_path.replace('rgb', 'ir')
        
        # Ê£ÄÊü•Êñá‰ª∂ÊòØÂê¶Â≠òÂú®
        if not os.path.exists(rgb_path) or not os.path.exists(ir_path):
            print(f"Warning: RGB or IR image not found: {rgb_path}, {ir_path}")
            return None, None, None, None
        
        # Âä†ËΩΩRGBÂíåIRÂõæÂÉèÔºåÂÆåÂÖ®Ê®°‰ªøÊï∞ÊçÆÂä†ËΩΩÂô®ÁöÑÈÄªËæë
        img_rgb_path = rgb_path
        img_ir_path = ir_path
        img_rgb = Image.open(img_rgb_path).convert("RGB")
        img_ir = Image.open(img_ir_path)
        pil_img_original = img_rgb.copy()
        pil_img_ir = img_ir.copy()

        # ‰∏éÊï∞ÊçÆÂä†ËΩΩÂô®ÂÆåÂÖ®‰∏ÄËá¥ÁöÑÂ§ÑÁêÜ
        np_rgb = np.array(img_rgb)
        np_ir = np.array(img_ir)
        if np_ir.shape[-1] == 3:
            np_ir = np_ir[..., 0]
        np_ir = np.expand_dims(np_ir, axis=-1)
        np_combined = np.concatenate([np_rgb, np_ir], axis=-1)
        img = Image.fromarray(np_combined)

        # Ëé∑ÂèñÂõæÂÉèÂ∞∫ÂØ∏
        w, h = img.size
        full_box_xyxy = torch.tensor([0.0, 0.0, float(w - 1), float(h - 1)], dtype=torch.float32)

        # ‰ΩøÁî®transformÂ§ÑÁêÜRGBTÂõæÂÉè
        input_dict = {'img': img, 'box': full_box_xyxy, 'text': text}
        input_dict = transform(input_dict)

        return input_dict['img'], input_dict['mask'], pil_img_original, pil_img_ir
        
    else:
        if not os.path.exists(img_path):
            print(f"Warning: Image not found: {img_path}")
            return None, None, None
        # IRÂõæÂÉèËΩ¨Êç¢‰∏∫RGBÔºà3ÈÄöÈÅìÔºâÔºå‰∏édataloader‰øùÊåÅ‰∏ÄËá¥
        pil_img = Image.open(img_path).convert('RGB')
        
        # ‰øùÂ≠òÂéüÂßãÂõæÂÉèÁî®‰∫éÂèØËßÜÂåñ
        pil_img_original = pil_img.copy()
        
        # Ëé∑ÂèñÂõæÂÉèÂ∞∫ÂØ∏
        w, h = pil_img.size
        full_box_xyxy = torch.tensor([0.0, 0.0, float(w - 1), float(h - 1)], dtype=torch.float32)
        
        # Â∫îÁî®ÂèòÊç¢
        input_dict = {'img': pil_img, 'box': full_box_xyxy, 'text': text}
        input_dict = transform(input_dict)

        return input_dict['img'], input_dict['mask'], pil_img_original


def save_gt_visualization(args, pil_img_original, pil_img_ir, text, gt_bbox, sample_idx, output_dir, model_name="model"):
    """‰øùÂ≠òGTÂèØËßÜÂåñÁªìÊûúÔºà‰ªÖÊòæÁ§∫ÁúüÂÆûÊ°ÜÔºâ
    ÂØπ‰∫éRGBTÊ®°ÊÄÅÔºö‰øùÂ≠òRGBÂõæ+GTÊ°Ü„ÄÅIRÂõæ+GTÊ°Ü„ÄÅ1‰∏™txtÊñá‰ª∂„ÄÅ1Âº†ÂéüÂõæÔºà‰∏çÂ∏¶Ê°ÜÔºâ
    
    Args:
        args: ÂèÇÊï∞ÂØπË±°ÔºåÂåÖÂê´modality„ÄÅdatasetÁ≠âÈÖçÁΩÆ
        pil_img_original: ÂéüÂßãRGBÂõæÂÉè
        pil_img_ir: ÂéüÂßãIRÂõæÂÉèÔºàÂèØÈÄâÔºâ
        text: ÊñáÊú¨ÊèèËø∞
        gt_bbox: ÁúüÂÆûËæπÁïåÊ°Ü
        sample_idx: Ê†∑Êú¨Á¥¢Âºï
        output_dir: ËæìÂá∫ÁõÆÂΩï
        model_name: Ê®°ÂûãÂêçÁß∞ÔºåÁî®‰∫éÊñá‰ª∂ÂëΩÂêç
        
    Returns:
        str: RGBÂõæÂÉè‰øùÂ≠òË∑ØÂæÑ
    """
    img_np = np.array(pil_img_original)
    
    h, w = img_np.shape[:2]

    if isinstance(gt_bbox, torch.Tensor):
        gt_bbox = gt_bbox.cpu().numpy()
    elif isinstance(gt_bbox, list):
        gt_bbox = np.array(gt_bbox)
    
    if len(gt_bbox) == 4:
        gt_x, gt_y, gt_w, gt_h = gt_bbox.astype(int)
        gt_x_min = gt_x
        gt_y_min = gt_y
        gt_x_max = gt_x + gt_w
        gt_y_max = gt_y + gt_h
    else:
        print(f"Warning: Unexpected gt_bbox format: {gt_bbox}")
        gt_x_min = gt_y_min = gt_x_max = gt_y_max = 0
    
    gt_x_min = max(0, min(gt_x_min, w - 1))
    gt_y_min = max(0, min(gt_y_min, h - 1))
    gt_x_max = max(0, min(gt_x_max, w - 1))
    gt_y_max = max(0, min(gt_y_max, h - 1))
    
    Path(output_dir).mkdir(parents=True, exist_ok=True)
    # 3. ‰øùÂ≠òÂéüÂõæÔºà‰∏çÂ∏¶Ê°ÜÔºâ- Âè™ÂØπRGBTÊ®°ÊÄÅ‰øùÂ≠ò
    original_path = os.path.join(output_dir, f"{model_name}_{sample_idx:06d}_original.jpg")
    cv2.imwrite(original_path, cv2.cvtColor(img_np, cv2.COLOR_RGB2BGR))
    # 1. ‰øùÂ≠òRGBÂõæ + GTÊ°Ü
    vis_img_rgb = np.ascontiguousarray(img_np)
    cv2.rectangle(vis_img_rgb, (gt_x_min, gt_y_min), (gt_x_max, gt_y_max), (0, 0, 255), 2)  # Á∫¢Ëâ≤ÁúüÂÆûÊ°Ü
    rgb_path = os.path.join(output_dir, f"{model_name}_{sample_idx:06d}_rgb.jpg")
    cv2.imwrite(rgb_path, cv2.cvtColor(vis_img_rgb, cv2.COLOR_RGB2BGR))
    
    # 2. ÂØπ‰∫éRGBTÊ®°ÊÄÅÔºå‰øùÂ≠òIRÂõæ + GTÊ°Ü
    if hasattr(args, 'modality') and args.modality == 'rgbt' and pil_img_ir is not None:
        img_ir_np = np.array(pil_img_ir)

        if img_ir_np.ndim == 2:
            img_ir_np = np.stack([img_ir_np] * 3, axis=-1)
        elif img_ir_np.ndim == 3 and img_ir_np.shape[2] == 1:
            img_ir_np = np.repeat(img_ir_np, 3, axis=2)
        
        vis_img_ir = np.ascontiguousarray(img_ir_np)
        cv2.rectangle(vis_img_ir, (gt_x_min, gt_y_min), (gt_x_max, gt_y_max), (0, 0, 255), 2)  # Á∫¢Ëâ≤ÁúüÂÆûÊ°Ü
        ir_path = os.path.join(output_dir, f"{model_name}_{sample_idx:06d}_ir.jpg")
        cv2.imwrite(ir_path, cv2.cvtColor(vis_img_ir, cv2.COLOR_RGB2BGR))
        

    
    # 4. ‰øùÂ≠òÊñáÊú¨Êñá‰ª∂
    txt_path = os.path.join(output_dir, f"{model_name}_{sample_idx:06d}.txt")
    with open(txt_path, 'w', encoding='utf-8') as f:
        f.write(text)
    
    return rgb_path


def save_visualization(args, pil_img_original, pil_img_ir, text, pred_bbox, gt_bbox, sample_idx, output_dir, model_name="model"):
    """‰øùÂ≠òÂèØËßÜÂåñÁªìÊûúÔºåÂàÜÂà´‰øùÂ≠òÈ¢ÑÊµãÊ°ÜÂíåÁúüÂÆûÊ°ÜÁöÑÂõæÂÉè
    
    Args:
        args: ÂèÇÊï∞ÂØπË±°ÔºåÂåÖÂê´modality„ÄÅdatasetÁ≠âÈÖçÁΩÆ
        pil_img_original: ÂéüÂßãRGBÂõæÂÉè
        pil_img_ir: ÂéüÂßãIRÂõæÂÉèÔºàÂèØÈÄâÔºâ
        text: ÊñáÊú¨ÊèèËø∞
        pred_bbox: È¢ÑÊµãÁöÑËæπÁïåÊ°Ü
        gt_bbox: ÁúüÂÆûËæπÁïåÊ°Ü
        sample_idx: Ê†∑Êú¨Á¥¢Âºï
        output_dir: ËæìÂá∫ÁõÆÂΩï
        model_name: Ê®°ÂûãÂêçÁß∞ÔºåÁî®‰∫éÊñá‰ª∂ÂëΩÂêç
        
    Returns:
        tuple: (pred_rgb_path, gt_rgb_path)
    """
    # ‰øùÂ≠òÈ¢ÑÊµãÊ°ÜÂõæÂÉè
    pred_rgb_path = save_pred_visualization(args, pil_img_original, pil_img_ir, text, pred_bbox, sample_idx, output_dir, model_name)
    
    # ‰øùÂ≠òGTÊ°ÜÂõæÂÉè
    gt_rgb_path = save_gt_visualization(args, pil_img_original, pil_img_ir, text, gt_bbox, sample_idx, output_dir, model_name)
    
    return pred_rgb_path, gt_rgb_path


def save_pred_visualization(args, pil_img_original, pil_img_ir, text, pred_bbox, sample_idx, output_dir, model_name="model"):
    """‰øùÂ≠òÈ¢ÑÊµãÂèØËßÜÂåñÁªìÊûúÔºà‰ªÖÊòæÁ§∫È¢ÑÊµãÊ°ÜÔºâ
    
    Args:
        args: ÂèÇÊï∞ÂØπË±°ÔºåÂåÖÂê´modality„ÄÅdatasetÁ≠âÈÖçÁΩÆ
        pil_img_original: ÂéüÂßãRGBÂõæÂÉè
        pil_img_ir: ÂéüÂßãIRÂõæÂÉèÔºàÂèØÈÄâÔºâ
        text: ÊñáÊú¨ÊèèËø∞
        pred_bbox: È¢ÑÊµãÁöÑËæπÁïåÊ°Ü
        sample_idx: Ê†∑Êú¨Á¥¢Âºï
        output_dir: ËæìÂá∫ÁõÆÂΩï
        model_name: Ê®°ÂûãÂêçÁß∞ÔºåÁî®‰∫éÊñá‰ª∂ÂëΩÂêç
        
    Returns:
        str: RGBÂõæÂÉè‰øùÂ≠òË∑ØÂæÑ
    """
    # Áõ¥Êé•‰ΩøÁî®ÂéüÂßãÂõæÂÉèÔºå‰∏çÈúÄË¶ÅÂèçÂΩí‰∏ÄÂåñ
    img_np = np.array(pil_img_original)
    
    # ËΩ¨Êç¢bboxÂà∞ÂÉèÁ¥†ÂùêÊ†á
    h, w = img_np.shape[:2]
    
    # Â§ÑÁêÜÈ¢ÑÊµãÊ°Ü - Ê®°ÂûãËæìÂá∫ÊòØsigmoidÂêéÁöÑÂΩí‰∏ÄÂåñÂùêÊ†á(x_center, y_center, w, h)ÔºåËåÉÂõ¥[0,1]
    if isinstance(pred_bbox, torch.Tensor):
        pred_bbox = pred_bbox.cpu().numpy()
    
    # È¢ÑÊµãÊ°ÜÊ†ºÂºèÔºöÂΩí‰∏ÄÂåñÁöÑ(x_center, y_center, w, h)
    # ÈúÄË¶ÅËΩ¨Êç¢‰∏∫ÂÉèÁ¥†ÂùêÊ†áÁöÑ(x_min, y_min, x_max, y_max)Áî®‰∫éÁªòÂà∂
    pred_x_center, pred_y_center, pred_bbox_w, pred_bbox_h = pred_bbox
    
    # Âü∫Á°ÄËΩ¨Êç¢ÔºöÂΩí‰∏ÄÂåñÂùêÊ†áËΩ¨ÂÉèÁ¥†ÂùêÊ†á
    pred_x_min = int((pred_x_center - pred_bbox_w / 2) * w)
    pred_y_min = int((pred_y_center - pred_bbox_h / 2) * w)  # Ê≥®ÊÑèÔºöËøôÈáåÁî®wÊòØÊ≠£Á°ÆÁöÑ
    pred_x_max = int((pred_x_center + pred_bbox_w / 2) * w)
    pred_y_max = int((pred_y_center + pred_bbox_h / 2) * w)  # Ê≥®ÊÑèÔºöËøôÈáåÁî®wÊòØÊ≠£Á°ÆÁöÑ
    
    # Êï∞ÊçÆÈõÜÁâπÂÆöÁöÑYËΩ¥ÂÅèÁßªË∞ÉÊï¥
    if hasattr(args, 'dataset'):
        if args.dataset == 'rgbtvg_mfad':
            pred_y_min -= 160
            pred_y_max -= 160
        elif args.dataset == 'rgbtvg_m3fd':
            pred_y_min -= 128
            pred_y_max -= 128
        elif args.dataset == 'rgbtvg_flir':
            pred_y_min -= 64
            pred_y_max -= 64
    
    # ÈôêÂà∂È¢ÑÊµãÊ°ÜÂú®ÂõæÂÉèËåÉÂõ¥ÂÜÖ
    pred_x_min = max(0, min(pred_x_min, w - 1))
    pred_y_min = max(0, min(pred_y_min, h - 1))
    pred_x_max = max(0, min(pred_x_max, w - 1))
    pred_y_max = max(0, min(pred_y_max, h - 1))
    
    # ÂàõÂª∫ËæìÂá∫ÁõÆÂΩï
    Path(output_dir).mkdir(parents=True, exist_ok=True)
    
    # ‰øùÂ≠òRGBÂõæÂÉèÔºà‰ªÖÈ¢ÑÊµãÊ°ÜÔºâ
    vis_img_rgb = np.ascontiguousarray(img_np)
    cv2.rectangle(vis_img_rgb, (pred_x_min, pred_y_min), (pred_x_max, pred_y_max), (0, 255, 0), 2)  # ÁªøËâ≤È¢ÑÊµãÊ°Ü
    rgb_path = os.path.join(output_dir, f"{model_name}_pred_{sample_idx:06d}_rgb.jpg")
    cv2.imwrite(rgb_path, cv2.cvtColor(vis_img_rgb, cv2.COLOR_RGB2BGR))
    
    # Â¶ÇÊûúÊòØRGBTÊ®°ÊÄÅÔºåËøòË¶Å‰øùÂ≠òIRÂõæÂÉèÔºà‰ªÖÈ¢ÑÊµãÊ°ÜÔºâ
    if hasattr(args, 'modality') and args.modality == 'rgbt' and pil_img_ir is not None:
        img_ir_np = np.array(pil_img_ir)
        # Â¶ÇÊûúIRÊòØÂçïÈÄöÈÅìÔºåËΩ¨Êç¢‰∏∫3ÈÄöÈÅìÁî®‰∫éÂèØËßÜÂåñ
        if img_ir_np.ndim == 2:
            img_ir_np = np.stack([img_ir_np] * 3, axis=-1)
        elif img_ir_np.ndim == 3 and img_ir_np.shape[2] == 1:
            img_ir_np = np.repeat(img_ir_np, 3, axis=2)
        
        vis_img_ir = np.ascontiguousarray(img_ir_np)
        cv2.rectangle(vis_img_ir, (pred_x_min, pred_y_min), (pred_x_max, pred_y_max), (0, 255, 0), 2)  # ÁªøËâ≤È¢ÑÊµãÊ°Ü
        ir_path = os.path.join(output_dir, f"{model_name}_pred_{sample_idx:06d}_ir.jpg")
        cv2.imwrite(ir_path, cv2.cvtColor(vis_img_ir, cv2.COLOR_RGB2BGR))
    
    # ‰øùÂ≠òÊñáÊú¨Âà∞txtÊñá‰ª∂
    txt_path = os.path.join(output_dir, f"{model_name}_pred_{sample_idx:06d}.txt")
    with open(txt_path, 'w', encoding='utf-8') as f:
        f.write(text)
    
    return rgb_path


def load_dataset(label_file):
    """Âä†ËΩΩÊï∞ÊçÆÈõÜÊñá‰ª∂
    
    Args:
        label_file: Êï∞ÊçÆÈõÜÊ†áÁ≠æÊñá‰ª∂Ë∑ØÂæÑ
        
    Returns:
        list: Êï∞ÊçÆÈõÜÂàóË°®
    """
    import torch
    
    if not os.path.exists(label_file):
        raise FileNotFoundError(f"Dataset file not found: {label_file}")
    
    print(f"Loading dataset from: {label_file}")
    data = torch.load(label_file, map_location='cpu')
    print(f"Total samples in dataset: {len(data)}")
    return data


def save_combined_pred_visualization(args, pil_img_original, pil_img_ir, predictions, img_filename, output_dir, model_name):
    """‰øùÂ≠òÂêàÂπ∂ÁöÑÈ¢ÑÊµãÂèØËßÜÂåñÁªìÊûúÔºàÊØè‰∏™ÂõæÁâá‰ª•Êñá‰ª∂Â§πÂΩ¢ÂºèÂ≠òÂÇ®Ôºâ"""
    import torch
    import numpy as np
    import cv2
    from pathlib import Path
    
    img_np = np.array(pil_img_original)
    h, w = img_np.shape[:2]
    
    # ‰∏∫ÊØè‰∏™ÂõæÁâáÂàõÂª∫ÂçïÁã¨ÁöÑÊñá‰ª∂Â§π
    img_base_name = Path(img_filename).stem
    img_folder = os.path.join(output_dir, img_base_name)
    Path(img_folder).mkdir(parents=True, exist_ok=True)
    
    # ÁîüÊàê‰∏çÂêåÈ¢úËâ≤Áî®‰∫éÂå∫ÂàÜ‰∏çÂêåÁöÑÈ¢ÑÊµãÊ°Ü
    colors = [
        (0, 255, 0),    # ÁªøËâ≤ - È¢ÑÊµãÊ°ÜÁî®ÁªøËâ≤
        (255, 0, 0),    # Á∫¢Ëâ≤
        (0, 0, 255),    # ËìùËâ≤
        (255, 255, 0),  # ÈªÑËâ≤
        (255, 0, 255),  # Á¥´Ëâ≤
        (0, 255, 255),  # ÈùíËâ≤
        (255, 128, 0),  # Ê©ôËâ≤
        (128, 0, 255),  # Á¥´ÁΩóÂÖ∞
    ]
    
    # 1. ‰øùÂ≠òRGBÂéüÂõæÔºà‰∏çÂ∏¶Ê°ÜÔºâ
    rgb_original_path = os.path.join(img_folder, "rgb_original.jpg")
    cv2.imwrite(rgb_original_path, cv2.cvtColor(img_np, cv2.COLOR_RGB2BGR))
    
    # 2. ÂØπ‰∫éRGBTÊ®°ÊÄÅÔºå‰øùÂ≠òIRÂéüÂõæÔºà‰∏çÂ∏¶Ê°ÜÔºâ
    if hasattr(args, 'modality') and args.modality == 'rgbt' and pil_img_ir is not None:
        img_ir_np = np.array(pil_img_ir)
        
        # ‰øùÂ≠òIRÂéüÂõæ
        ir_original_path = os.path.join(img_folder, "ir_original.jpg")
        if img_ir_np.ndim == 2:
            cv2.imwrite(ir_original_path, img_ir_np)
        else:
            cv2.imwrite(ir_original_path, cv2.cvtColor(img_ir_np, cv2.COLOR_RGB2BGR))
    
    # 3. ‰øùÂ≠òRGBÂõæ + ÊâÄÊúâÈ¢ÑÊµãÊ°Ü
    vis_img_rgb = np.ascontiguousarray(img_np.copy())
    
    # Êî∂ÈõÜÊâÄÊúâÊñáÊú¨
    all_texts = []
    
    for i, pred in enumerate(predictions):
        bbox_pred = pred['bbox']
        text = pred['text']
        sample_idx = pred['sample_idx']
        
        # Â§ÑÁêÜbbox
        if isinstance(bbox_pred, torch.Tensor):
            bbox_pred = bbox_pred.cpu().numpy()
        elif isinstance(bbox_pred, list):
            bbox_pred = np.array(bbox_pred)
        
        if len(bbox_pred) == 4:
            # ÂÅáËÆæÊòØxywhÊ†ºÂºèÔºåËΩ¨Êç¢‰∏∫xyxy
            x_center, y_center, bbox_w, bbox_h = bbox_pred
            x_min = int((x_center - bbox_w / 2) * w)
            y_min = int((y_center - bbox_h / 2) * h)
            x_max = int((x_center + bbox_w / 2) * w)
            y_max = int((y_center + bbox_h / 2) * h)
        else:
            print(f"Warning: Unexpected pred_bbox format: {bbox_pred}")
            continue
        
        # ÈôêÂà∂Âú®ÂõæÂÉèËåÉÂõ¥ÂÜÖ
        x_min = max(0, min(x_min, w - 1))
        y_min = max(0, min(y_min, h - 1))
        x_max = max(0, min(x_max, w - 1))
        y_max = max(0, min(y_max, h - 1))
        
        # ÈÄâÊã©È¢úËâ≤
        color = colors[i % len(colors)]
        
        # ÁîªÊ°Ü
        cv2.rectangle(vis_img_rgb, (x_min, y_min), (x_max, y_max), color, 2)
        
        # Ê∑ªÂä†Ê†áÁ≠æÔºàÊ°ÜÁöÑÁºñÂè∑Ôºâ
        cv2.putText(vis_img_rgb, f"{i+1}", (x_min, y_min-5), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)
        
        # Êî∂ÈõÜÊñáÊú¨
        all_texts.append(f"{i+1}. {text}")
    
    # ‰øùÂ≠òRGBÂõæ + È¢ÑÊµãÊ°Ü
    rgb_pred_path = os.path.join(img_folder, f"rgb_with_{model_name}_pred.jpg")
    cv2.imwrite(rgb_pred_path, cv2.cvtColor(vis_img_rgb, cv2.COLOR_RGB2BGR))
    
    # 4. ÂØπ‰∫éRGBTÊ®°ÊÄÅÔºå‰øùÂ≠òIRÂõæ + ÊâÄÊúâÈ¢ÑÊµãÊ°Ü
    if hasattr(args, 'modality') and args.modality == 'rgbt' and pil_img_ir is not None:
        img_ir_np = np.array(pil_img_ir)
        
        if img_ir_np.ndim == 2:
            img_ir_np = np.stack([img_ir_np] * 3, axis=-1)
        elif img_ir_np.ndim == 3 and img_ir_np.shape[2] == 1:
            img_ir_np = np.repeat(img_ir_np, 3, axis=2)
        
        vis_img_ir = np.ascontiguousarray(img_ir_np.copy())
        
        # ÁîªÊâÄÊúâÈ¢ÑÊµãÊ°ÜÂà∞IRÂõæ‰∏ä
        for i, pred in enumerate(predictions):
            bbox_pred = pred['bbox']
            
            if isinstance(bbox_pred, torch.Tensor):
                bbox_pred = bbox_pred.cpu().numpy()
            elif isinstance(bbox_pred, list):
                bbox_pred = np.array(bbox_pred)
            
            if len(bbox_pred) == 4:
                x_center, y_center, bbox_w, bbox_h = bbox_pred
                x_min = max(0, min(int((x_center - bbox_w / 2) * w), w - 1))
                y_min = max(0, min(int((y_center - bbox_h / 2) * h), h - 1))
                x_max = max(0, min(int((x_center + bbox_w / 2) * w), w - 1))
                y_max = max(0, min(int((y_center + bbox_h / 2) * h), h - 1))
                
                color = colors[i % len(colors)]
                cv2.rectangle(vis_img_ir, (x_min, y_min), (x_max, y_max), color, 2)
                cv2.putText(vis_img_ir, f"{i+1}", (x_min, y_min-5), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)
        
        ir_pred_path = os.path.join(img_folder, f"ir_with_{model_name}_pred.jpg")
        cv2.imwrite(ir_pred_path, cv2.cvtColor(vis_img_ir, cv2.COLOR_RGB2BGR))
    
    # 5. ‰øùÂ≠òÂêàÂπ∂ÁöÑÊñáÊú¨Êñá‰ª∂
    txt_path = os.path.join(img_folder, f"{model_name}_predictions.txt")
    with open(txt_path, 'w', encoding='utf-8') as f:
        f.write(f"Image: {img_filename}\n")
        f.write(f"Model: {model_name}\n")
        f.write(f"Total predictions: {len(predictions)}\n")
        f.write("=" * 50 + "\n\n")
        for text_line in all_texts:
            f.write(text_line + "\n\n")
    
    return rgb_pred_path


def generate_prediction_statistics(output_dir, prediction_stats, dataset, modality, model_name):
    """ÁîüÊàêÈ¢ÑÊµãÁªüËÆ°Êä•Âëä"""
    from pathlib import Path
    
    # ÊéíÂ∫èÔºöÊåâÈ¢ÑÊµãÊï∞ÈáèÈôçÂ∫èÊéíÂàó
    prediction_stats.sort(key=lambda x: x['predictions'], reverse=True)
    
    # ËÆ°ÁÆóÁªüËÆ°‰ø°ÊÅØ
    total_images = len(prediction_stats)
    total_predictions = sum(item['predictions'] for item in prediction_stats)
    avg_predictions = total_predictions / total_images if total_images > 0 else 0
    
    # ÁªüËÆ°È¢ÑÊµãÊï∞ÈáèÂàÜÂ∏É
    prediction_counts = {}
    for item in prediction_stats:
        count = item['predictions']
        prediction_counts[count] = prediction_counts.get(count, 0) + 1
    
    # ‰øùÂ≠òÁªüËÆ°Êä•Âëä
    stats_path = os.path.join(output_dir, "prediction_statistics.txt")
    with open(stats_path, 'w', encoding='utf-8') as f:
        f.write("=" * 80 + "\n")
        f.write(f"{model_name.upper()} PREDICTION STATISTICS REPORT\n")
        f.write("=" * 80 + "\n\n")
        
        f.write(f"Model: {model_name}\n")
        f.write(f"Dataset: {dataset}\n")
        f.write(f"Modality: {modality}\n")
        f.write(f"Generated: {Path().absolute()}\n\n")
        
        f.write("SUMMARY:\n")
        f.write("-" * 40 + "\n")
        f.write(f"Total Images: {total_images}\n")
        f.write(f"Total Predictions: {total_predictions}\n")
        f.write(f"Average Predictions per Image: {avg_predictions:.2f}\n\n")
        
        f.write("PREDICTION COUNT DISTRIBUTION:\n")
        f.write("-" * 40 + "\n")
        for count in sorted(prediction_counts.keys()):
            images_with_count = prediction_counts[count]
            percentage = (images_with_count / total_images) * 100
            f.write(f"{count} predictions: {images_with_count} images ({percentage:.1f}%)\n")
        f.write("\n")
        
        f.write("DETAILED LIST (sorted by prediction count):\n")
        f.write("-" * 80 + "\n")
        f.write(f"{'Rank':<6} {'Image':<50} {'Predictions':<12}\n")
        f.write("-" * 80 + "\n")
        
        for i, item in enumerate(prediction_stats, 1):
            f.write(f"{i:<6} {item['image']:<50} {item['predictions']:<12}\n")
    
    # ÂêåÊó∂ÁîüÊàêCSVÊ†ºÂºèÁöÑÁªüËÆ°Êñá‰ª∂
    csv_path = os.path.join(output_dir, "prediction_statistics.csv")
    with open(csv_path, 'w', encoding='utf-8') as f:
        f.write("Rank,Image,Predictions\n")
        for i, item in enumerate(prediction_stats, 1):
            f.write(f"{i},{item['image']},{item['predictions']}\n")
    
    print(f"\nüìä {model_name.upper()} Prediction Statistics:")
    print(f"   Total Images: {total_images}")
    print(f"   Total Predictions: {total_predictions}")
    print(f"   Average per Image: {avg_predictions:.2f}")
    print(f"   Max Predictions: {max(item['predictions'] for item in prediction_stats) if prediction_stats else 0}")
    print(f"   Min Predictions: {min(item['predictions'] for item in prediction_stats) if prediction_stats else 0}")